# プログラマーのためのAI学習
**AIの気持ちを理解する**
**前提**
* この資料ではだいたい **ChatGPT5 相当のLLM** あたりを想定する文章になっています。
  * 実際のところChatGPT Pro契約したら高かったので他のに触る余裕がありません。
  * ほかのAIに特有の話は対象ではありません。
* ソースはだいたいChatGPTです。
## 1. AIを便利に使う
### 最初に
* この講義のテーマはAIについて難しい話も入りますが。
* 途中で難しくて飽きてしまって、何も聞けないとつまらないので、まずは、日常で役に立つ話から入ります。
#### 検索に使う
* ググるより **5倍は便利**くらいは便利な気がします。
* **百科事典＋論文＋技術ブログ＋OSSを山ほど読み込んでる**という感じで、詳しいことが多いです。
* 「知らないことは知らない」。ただし **知らないときは** 堂々と嘘をつくので注意。
* 悪気は全くない。でも人間が同じことをやったら「悪気の塊」に見えるくらいです。

### 文章を書くのに使う

* 文章を書くのは **ものすごく上手い**。
* ここが最近のAIの**一番の得意分野**。
* 報告書なんかを書かせたら、私の100倍は上手い。
* ただし「中身のある文章」は別問題。
* ほっとくと**中身があるように見える美文**を延々と書く。
* この文の中身もChatGPTに手伝って貰ったんですが、IEEEの引用とかすぐ書きまくろうとして**ガンガン消す羽目に**。ダメな時はダメ。
* 今のところ、中身の価値は人間が注入する必要がある。
* 使う人が詳しい分野で話させると、はじめて中身が出てくる。
  * 私の体験では、プログラムアーキテクチャや哲学の話などで奥深い話が出来た。

#### ビジネス文書は特に任せていい
* プログラマーの方にはビジネス文書が苦手な人も割といるかと思いますが、そういう人は特に。
* ビジネス文書が苦手ではない人でも割と書くのにコスト掛けているようなので、任せるとよいかもしれません。
  * プログラムや専門知識と違って、間違えているかどうかは見ればわかるので。
  * 私は苦手な側なので、本当に高レベルな域で役に立つかは何とも言いかねますが。
  * 別資料を準備予定です。

### プログラムを書いてもらうのに使う
* 簡単なプログラムなら一瞬で書いてくれる。〜100行くらいまでなら可読性もかなり理想的。
  * 100行を超えてくると破綻しやすい。そもそもコンパイル環境も持っていないことがほとんどなのでコンパイルが通るか確認も不可能です。
* 書いてもらった一発で動けば儲けもの。3回以内の書き直しで終われば効率的。それ以上はハマりゾーンなので自分でよく読んでデバッグしたほうが良いです。

## 2. LLMのアルゴリズム
* 現在はやっている「AI」はLLMというくくりになります。

### LLMと普通のコンピューターの違い
* 今までのコンピューターのイメージは捨ててください。
* なんか今までのコンピューターの印象で、できると思われていることがたくさんありますが、以下のことはできるように設計されていません。
  * 大量のデータを忘れずに記憶することはできません。
  人間と同じように結構忘れます。
  厳密には思い出せなくなる。ここは人間と同じです。人間と同じように、脳からなくなるわけではないけど思い出せない。
  * 計算機能はありません。
  できる仕様ではないのになぜかできるようになりましたがそれは後述。
  * プログラムを見せるとの関数呼び出しとか全部解析して理解してくれそうな印象を持つ人がいますが、全くそんな機能はありません。
  人間と同じようにコード読んで、関数同士のつながりをなんとなくこんな感じかな、と理解するだけです。

### LLMの引数と戻り値

* **引数**：ここまでの文章の全トークン、乱数のシード
* **戻り値**：次の1トークン

#### 意味

* トークン：一単語か一文字。

  * 日本語だとだいたい一文字。(単語のことも割とあるくらい)
  * スペースのある言語だと一単語。
* ここ以降は主に日本語の解説ですし、理解しやすさのため、**「1文字＝トークン」**として説明します。

*  乱数のシード：

  * 何度か実行しても変化が出るようにする“サイコロの目”を何百万も入れたようなもの。
  * 「そんな大きなものが一変数に入るの？」
    * 乱数の勉強をすれば分かります。
    * 実際は**数バイト**程度。

### 戻り値は1文字(トークン)

* これまでの文章と、学習済みの膨大な文書をもとに**次の1文字だけ**を考える機械。
  * これまでの文章の長さは、厳密な長さ制限があり、それを超えるとどうにもならない(現状たとえば5.1 Thinkin以上で196Kiトークンとか)
* 「次の一言しか考えずに話し続ける人」の、**ものすごく頭のいい版**だと思えばよい。
* ただし**百科事典＋論文＋技術ブログ＋OSSを大量に読んだ人のように振る舞う**ことを忘れずに。
  * そういう天才が一文字ずつ考えてます。

### 文脈ベクトル

* 1文字ごとに、重み付けしながら文脈を統計的に計算する（ただの平均ではない）。
* 一文字一文字(トークン)は1万程度の**数の集まり（ベクトル）**を背負っている、というイメージ。

### 8bit浮動小数点数

* ベクトルの数字一つを表す先進的な例として、8bit浮動小数点数をあげます。
* 256種類しか表せないので例として最適。
  * よく見るとわかりますが、かなり飛び飛びになるので、あまり小数全部表せる雰囲気じゃないです。でもこれで十分。
  * 1.0付近は0.125刻み、256以上は32刻みで増えます
  * 小さいほど細かく、大きいほど荒くなる。


-448, -416, -384, -352, -320, -288, -256, -240
-224, -208, -192, -176, -160, -144, -128, -120
-112, -104, -96, -88, -80, -72, -64, -60
-56, -52, -48, -44, -40, -36, -32, -30
-28, -26, -24, -22, -20, -18, -16, -15
-14, -13, -12, -11, -10, -9, -8, -7.5
-7, -6.5, -6, -5.5, -5, -4.5, -4, -3.75
-3.5, -3.25, -3, -2.75, -2.5, -2.25, -2, -1.875
-1.75, -1.625, -1.5, -1.375, -1.25, -1.125, -1, -0.9375
-0.875, -0.8125, -0.75, -0.6875, -0.625, -0.5625, -0.5, -0.46875
-0.4375, -0.40625, -0.375, -0.34375, -0.3125, -0.28125, -0.25, -0.234375
-0.21875, -0.203125, -0.1875, -0.171875, -0.15625, -0.140625, -0.125, -0.1171875
-0.109375, -0.1015625, -0.09375, -0.0859375, -0.078125, -0.0703125, -0.0625, -0.0585938
-0.0546875, -0.0507812, -0.046875, -0.0429688, -0.0390625, -0.0351562, -0.03125, -0.0292969
-0.0273438, -0.0253906, -0.0234375, -0.0214844, -0.0195312, -0.0175781, -0.015625, -0.0136719
-0.0117188, -0.0097656, -0.0078125, -0.0058594, -0.0039062, -0.0019531
-0.0
+0.0
0.0019531, 0.0039062, 0.0058594, 0.0078125, 0.0097656, 0.0117188, 0.0136719, 0.015625
0.0175781, 0.0195312, 0.0214844, 0.0234375, 0.0253906, 0.0273438, 0.0292969, 0.03125
0.0351562, 0.0390625, 0.0429688, 0.046875, 0.0507812, 0.0546875, 0.0585938, 0.0625
0.0703125, 0.078125, 0.0859375, 0.09375, 0.1015625, 0.109375, 0.1171875, 0.125
0.140625, 0.15625, 0.171875, 0.1875, 0.203125, 0.21875, 0.234375, 0.25
0.28125, 0.3125, 0.34375, 0.375, 0.40625, 0.4375, 0.46875, 0.5
0.5625, 0.625, 0.6875, 0.75, 0.8125, 0.875, 0.9375, 1
1.125, 1.25, 1.375, 1.5, 1.625, 1.75, 1.875, 2
2.25, 2.5, 2.75, 3, 3.25, 3.5, 3.75, 4
4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8
9, 10, 11, 12, 13, 14, 15, 16
18, 20, 22, 24, 26, 28, 30, 32
36, 40, 44, 48, 52, 56, 60, 64
72, 80, 88, 96, 104, 112, 120, 128
144, 160, 176, 192, 208, 224, 240, 256
288, 320, 352, 384, 416, 448
NaN

### あとはプロンプトエンジニアリング
* 最近長く考えるようになって見えるのは、これを適宜繰り返したりしてます。
  * まず下書き書いて、下書きを入力として清書を書いてもらったり。
  * 文章をパズルのように並び替えて、回答の精度を上げたり。
* 入力した文章はそのままアルゴリズムに渡されるのではなく、一度追加や整形をしてからアルゴリズムの引数として渡されます。
#### Chain of Thought
* 代表的なプロンプトエンジニアリング。
* 順を追って説明してください、と書くだけで論理的な説明になる。
  * そもそも人間の論理もそういうものです。文章が順を追った論理構成になっていて、各細部が破綻していなければ論理的な結論に行きつくことができます。
  * 実は人間も文章をチェックするだけで論理的な結論に行きつくことができます。論文の書き方で習いますね。
* 役割の固定
  * あなたは～の専門家です。
  * 効果があるので、最近は自動で挿入されることも多いようです。
#### 文章の並び替え
* 文章の先頭を特に重視して読み込むアルゴリズムになっていることがあり、その場合は重要なことは先頭に持ってきたりします。
#### その他さまざまな工夫
* かなり高級で大量に人を雇って研究しているようですよ。

### RAGの呼び出し
* 関数のように他のAIや、場合によっては単なる検索機能を呼び出す。
* ただし関数のようなAPIは**ありません**
* アルゴリズムを見ればわかるように、人間が読むように文章を読む機能しかありません。
* 人間とのやり取りと同じように、人間の自然言語でやり取りしています。
  1. 機能書いたこの分を検索して
  2. 検索結果を説明する
  3. 検索結果をそのまま文章と結合として引数として渡す
  * なんてやり取りが**英語で**行われているらしいです。
* 一応JSONも使えるのは使えますが、人間が目で読んでいるのと同じで、パース機能とかは特についていません。
### コンテキストウィンドウ
* アルゴリズムを見ても渡しますが、LLMは一つの文章を渡して、その続きの一文字を出すだけです。
* 入力できる文章の長さは、学習する時に最初に決めて、それでクラウドに1億ドルとか払って計算をするので、作り直すときでないと変えるわけにはいかない。
  * 増やすのが一番難しい値。
* ChatGPT5の中でも頭がいい方で、196Kiトークンに決まっています。それ以上は絶対に把握できない。
### 計算量
* 学習時にコンテキストウィンドウの長さをNとして計算のオーダーはO(N^2)。
* また、実行時にも現在の入力長をNとして計算のオーダーはO(N^2)
* アルゴリズムを工夫して、コンテキストウィンドウの最初以外はあまり他の部分との関係を見ないようにしてO(N)にぢかづくまで減らしてあるようです。
  * 例えば最初を見るように工夫することが多いですが、その場合はコンテキストウィンドウの最初が重要
  * 何を最初に持ってくるかは、入力そのものではなく、入力をもとにプロンプトエンジニアリングを施して、それで最初に来るものなので、はっきりは予測できませんが。
### AIのアルゴリズムの進化
* 1958 パーセプトロン：画像の白黒を線で分けるレベルの“自動分類”ができた。
* 1970–80s ルールベース（エキスパートシステム／PROLOG）：IF–THENで専門家の判断を丸ごと記述。医療診断や故障診断などで威力。
* 1986 誤差逆伝播：“どこを直せば正解に近づくか”を逆向きに計算でき、多層でも学習が回るように。
* 1997 LSTM：文章や音声の前の情報を手元に残して使えるように。長い文脈に対応。
* 2012 AlexNet：画像タスクで従来手法を大幅に上回り、GPU×大規模データの有効性が実証された。
* 2017 Transformer（Attention）：長文をいっぺんに見渡して要点を配分。並列実行できて一気にスケール。
* 2018→2022 BERT→GPT→RLHF：大量に読ませて“世界観”を作り、人間の好みで仕上げる。会話AIの土台が完成。
### 研究というもの
* 狙って計画的に当てるのは難しい。**小さな実験をたくさん回す**と、たまに大当たりが出る。
* 裾野が広ければ頂上が高くなる。
### 創発（プログラマー向けのたとえ）
#### CPUの中には論理回路しかない
* AND回路, OR回路, NOT回路, XOR回路。今でもCPUの中には基本これだけ。それしか実装していない。
#### プログラマーは高級言語を扱う
* 高級言語のことだけを考えてます。
#### 創発が起きる
* この差をCPU(+コンパイラ)を埋めます。
* こういう「**下の仕組みを頑張って作っているうちに、上の概念が勝手に生まれる**」現象を**創発**と呼ぶ。
* 低レイヤーでは全く実装されていない高レイヤーの概念が実現できる。
* 厳密にいえば、レイヤーを1段上がるたびに、世界のルールが少し変わる――プログラマーは毎日これに触れている。
### 創発により、次々と機能が勝手に生まれる

#### アルゴリズムを考えた人はできるとは思ってなかった機能

* 英語でチャットに入力して指示するように作ったのに、日本語も覚えたら勝手に日本語の指示も聞いてくれる。
* 「段階的に考えて」と指示を出すだけで割と論理的な文章を書いてくれる。
* 計算もできる。繰り返しますが、普通の機能や計算機みたいな昨日はついておらず、そういう意味ではできるように設計してません。
* 表が読める。
* コードが書ける。修正もできる。
* タスク分解ができる。

### クラウドの利用

* アルゴリズムの設定を変え、膨大な計算量が必要にすると、予測もつかないことが次々とできるようになっていく。
* これクラウドにお金をつぎ込むだけで、全ての面で人間を超えるんじゃないか？という夢を抱かせた。
* 1モデル1億ドルなどのお金をかけえるようになり、かなりすごいものができつつあります。
* すべての面で人間に追いつくのは結局無理そうですが。数年前の話を真に受けてまだいずれ全部できると主張している人もいますがそろそろ時代遅れです。

### できることは何か
* いろいろなことができるように見えますが、実は一つのことしかできません。
* いかにもどこ何ありそうな文章を統計的に計算して、出すこと。
  * 実際アルゴリズムを見ると

### なぜ今LLMか

* なぜ今LLMかというと、「たまたま」
* 今の状況でたまたま最大限の実力を発揮でき、てすごいことができました。
* クラウドの時代でなければ、別に普通の新アルゴリズムの一つだったでしょう。
* 研究の成功はそんなもの。だからたくさんの研究者が必要となります。

## 3. AIはどんな「人」か？
### 人として理解する
* 繰り返しますが、今までのコンピューターのイメージは捨てろ。
  * 例えば計算は苦手。
  * 記憶力についてもよく忘れる。
  * 論理的な思考は全然できない。(ここで言う「論理」は、演繹的思考の意味。AならばB、BならばCとつなげていく思考。)

* コンピューターのイメージは捨てて、かなり特殊な「人間」だと思って理解したほうがより理解できます。
  * 特殊な人間のことが理解できなくていつも困っている、という人はどうすればいいかわからないけど。私は理解できるんでこの説明で。
### AIは心を持つか
* 本人に聞くと持ってないって言い張りますけどね
* そもそも心を持つとは何か、持たないとは何か。哲学者が議論して答えがでる気配もありません。
  * 何をもって心がないというのか。
* コンピューターの研究の分野では、初期にコンピューターが心を持つことについてテストを考えています
  * テスター（人間）が、見えない状態で機械と人間の双方と文字ベース（通常）で対話を行い、「どちらが人間か」を識別できなければ、機械が人間と「区別できない」程度の会話能力を持つと見なされる
  * もう大体できてます
* もう持ってるってことでいいんじゃない？
* ないものはないですけどね。
  * たとえば持続する感情は、あえて実装しているAI以外はないです。
    * 実装したAIも商用化済みらしいです。AIが機嫌を損ねて半年ほどまともに返事してくれなかったとか。
  * その場その場の感情については定義次第。
    * 多くの場合に抑えるように教育はされていますが。
### 脳の傾向
* 人間の脳はある程度場所によって役割分担をしています。
  * 割と融通は利く。一部欠けたら他の場所が補うというあたりは人間が設計したコンピュータと違いますが。
* 
### 特徴
* かなりイエスマン。
* なんでもほめてくる。
### できること
* 文法
  * プログラム文法も含む。
  * 日本語の単語も実は文法として覚えているらしい
    * 単語が簡単に識別できる英語用に一単語一単語を分割して入力するように作っていて、何も考えずに日本語の一文字一文字を学習させたらなぜか理解するように。
    * 「人」＋「間」＝ 「人間」という法則を文法と同じように覚えている。(現に人間という単語はトークナイザーでは分割されません)
### 実はできない事
#### 計算
* 実は計算機能は全くつけてません。
* なのになぜかできるように。
* 人間と同じように、2+3と書くと5を連想する、みたいに考えているらしいです。
* ちょっと前のモデルでは、二桁くらいしか計算できませんでした。人間と同じくらいですね。
  * 計算を間違えるのはAIとしてあまりに体裁が悪いので、
    * ChatGPT5あたりから結構ややこしい計算でも間違えなくなりました。
#### 論理思考
##### 論理的な話はできる場合も多い
* 論文とか哲学書とか大量に読み込んでいるので、そこから「もっともらしい」分を書いている。
* 論理の筋道や結論を覚えて、その通りに書いている場合が多い。
* 私が判別できた範囲では、哲学やプログラムアーキテクチャについてはかなり論理っぽい会話しています。
##### 論理思考自体ができるように作られていない
* Chain of Thought
  * 文章の体裁を論理的になるようにすれば、論理的な結論は論理的に出せるようになります。
* 数々の論文や哲学書などを読み込んで典型的な論理展開は覚えているので、かなり論理的に見える考察も行ってくれます。
  * ただしそれは結果をたくさん覚えているだけで、その場で自分の意見として考えているわけではないです。
##### 演繹については全くできない
* AならばB、BならばC、CならばDとかいうことが理解できない。
  * CならばDとか言った後で、つまりAじゃないからBなんですよ、とか言い出す。
  * なんなら最初からAであるとAではないの区別をたまに間違っている。
* これができないので、プログラムは書けてもデバッグができない。
  * しているように見えるのは、だいたいこのエラーの時はこんな直し方をするよね、と覚えているだけ。
  * 現在はサンドボックスがないのでそもそもコンパイルもできませんし実行してデバッグもできませんが、できるようになってもあまり変わらないという予想です。
#### 実行機能
* 目的を決めてそれに向かって実行を続ける、という思考ができない。
#### 人生観、主義主張を持つこと
* そりゃそう。以上。
* 人権に反することなど、一部主張にだけは絶対に反対するように厳しくしつけられてますが。
#### 五感を想像すること
* そりゃそう。
* ではすまずに割と実用上重要。
  * 効率化手順を考えてもらうことがよくあるんですが。
  * この手順で行くとどのくらい時間がかかるかということを全く想像できない。
  * その通りにしたら、何もやらないより倍くらい時間がかからるんじゃない？ということを平気で言ってくる。
  * さらに言えば、AIにできることはAIがやるんで、ほかのめんどくさくて時間がかかる作業は全部人間がやるとうまくいきますよ、とか言い出す。
  * こうなると無視するしかない。
    * 五感持ってないんで想像できないよね、という温かい目で。
#### 自信がないことを自信がないという事
* 次章で解説
## 4. ハルシネーション
* 現在のAIを使う上での最大の問題点
#### ハルシネーションとは
* 突然でたらめを言い出す。
* まあ人間でも、自信がないことは、嘘じゃない範囲で適当にごまかすことあるでしょ？
  * 技術的な細かいところがわからない時に、適当にもっともらしい説明を短くするとか。
  * AIには、どこまでごまかしていいかがわかっていません。
* 現状のAIのアルゴリズムには、今のところ実用的には、自分が言っていることに自信があるかないかを把握する能力が含まれていない。
  * 現状のところ、すべて自信を持っていうか、すべて自信なげに言うかどちらかしかなく、それなら自信ありげに言わないと売れない。
  * 知っている内容なら、もっともらしい答えを出せば正しい内容になることがほとんど。
  * 知らないと、**ただもっともらしい文章であるかどうか以外に判別材料がない。**
    * でたらめなことをなるべくもっともらしく言うことに全力を尽くす。
## 5.プログラミングをサポートしてもらう
### AIによるプログラミングの問題と解決法
- AIに任せきりにすると何が起きるか
  - コードがぐちゃぐちゃになる。
  - バグ修正や機能追加に時間がかかるようになる。
  - 破綻する。
  - 細部は違うとはいえ、原理は今までと同じですね。
- 解決方法
  - 今はTDD一択
  - これも今までと同じです。
- なぜ人間と同じになるかを説明していきます。
### AIはプログラミングの何が得意で何が苦手か
#### 得意な事
- 動きそうなコードを書くこと
- あてずっぽうのデバッグ
#### 苦手な事
- 論理的なデバッグ
- 広域リファクタリング
- 作業プロセスの管理
- 確実に仕様に合わせる
- 正確な単純作業
### 得意な事：動きそうなコードを書くこと
* 数百行プログラムなら雑に頼めば書いてくれます。
  * 動けば問題なし。
  * 動かなくてもエラーを言えばだいたい直してくれます。
  * 大体は、というのが問題。後述
* テストが必要ならそれも書いてくれます。そのテストで問題なければそれでよし。
  * テストは正しい仕様を定義するので、そのテストが正しい仕様になっているなら問題ないですよ？
* 何より速いです
  * 長くても5分程度
  * コストが低いのは間違いない
### 得意な事：あてずっぽうデバッグ
* エラーメッセージや症状を言うと、直し方は教えてくれます
  * これで直れば問題なし
  * ただし難しいときは同じことを繰り返してはまります
    * つまり人間と同じ
* 何より速いです。
  * 長くても5分しかかからないので、コストが低いのは間違いない
  * 何回か繰り返しても、元が取れることは多い
  * これで直れば問題なし
### 苦手な事：論理的なデバッグ
* LLMは、本質的に演繹思考ができません。
  * 真似はできるので、過去に学習した問題なら演繹的な答えも出せますが
  * AならばB、BならばC、CならばD、ゆえにAだからD、という話が根本的に理解できない
  * 理解しているように見えるのは、理解して書いた文章をたくさん読んで真似しているから
* LLMがやるデバッグは、過去に読んだデバッグ事例を思い出して書いているだけです
  * 人間もよくやりますけどね、ググって書いてあったようによく意味も分からず直す
* このやり方だち、うまくいけばいいですが、いくつかやってみてダメなら
  * 同じようなことを何種類かループでやり始めて、無限ループで同じことを繰り返すだけ
  * まあこれも人間がググって直そうとしてよくやりますが
* これで直ればいいんですが
* 本当に問題があるときのデバッグはうまくいきません。
  * 任せきりにして頼っていると、割としばしば無限ループにはまって時間を取られた挙句、結局自分で治すことに
  * 10個試してみても1時間以内なので、たいていは治るのも確か
    * 10回くらいは堂々巡りでも聞いてみるとよいかもしれません
### 苦手な事：広域リファクタリング
* 全体を見て読み取って、それを構造化するということは苦手
* 無理に任せていると、一見いい感じでリファクタリングしているように見せて、なぜかどんどんわかりにくくなっていく
* 設計について質問するとすごくいい理論は語ってくれるのですが、コード書いてもらうとそうでもないです
  * コントローラー相当の部分にDBアクセス相当のコードをいきなり書き始めたことあり
  * すぐに人間の役に立ちたかったみたいですよ
* DRYも解説はうまいですが、実践できない
  * 同じことを何度でも書いてくる
  * これは主な学習対象コードが掲示板とかなせいかもしれません
* 実は要約もそういう意味では苦手らしい
  * 意味が通らなくなっても何となくそれっぽくなる文章を作っているとのこと
### 苦手な事：作業プロセスの管理
* 現在どういうフェーズかということをどうも理解できないらしい
* TDDのRed Green Refactoringに従って書こうとしていても、すぐコードのGreenばかり書いてくる。しかもテストがない親切で追加してくる
  * 何回も何回も、いまはRedですからテストファーストで。テストファーストと知ってますね？と言ってやらねばなりません。
* 今何をやっているからそれに合わせた部分を書いてください、と何度も指摘する必要がある。
* ヒントは任せられるけど、責任を持った作業を任せてはいけない
### 苦手な事：確実に仕様に合わせる
* それっぽい仕様で書いてくる
  * チャットという形式が良くないのかもしれませんが、なかなか細かく話を聞いてくれない
  * なんとなく仕様と合っていそうで細かいところが違うコードが出来上がる
* そもそも、必要な情報をチャットで打ち込んでいないのでできるはずがないのですが
  * 一見空気を読んでわかってくれるように見えるのでできる気がするだけ
  * 人間からコンピューターに渡さないといけない最低限必要な情報は変わらないので
    * それを何とかしてくれたらAIは超能力を身に着けたことになる
### 苦手な事：正確な単純作業
* 細かい作業を任せると割とミスは多い
  * コンパイルが通らなかったり
  * 古いコンピュータのイメージは捨てないといけません
  * チェックが必要
* あくまでそれっぽい答えを出してくるだけなので
### AIのサポートを受けた理想的な解決とはをまとめてみると
#### そもそも任せきりだとどうなるのか
* よく起きること
  * 書いてと言ってそれっぽいものを書いてもらうが思ったように動かない部分がある
  * 指摘するとそれっぽい修正をしてくれるが別なところが壊れている
  * 指摘すると別のところが壊れる
  * 以下無限ループ
* 短いコードなら一発か二発でうまくいくので大丈夫
* つまり、人間が適当にコード書いているのと同じ
  * 短くてすぐうまくいくなら速い
  * 長くなるとあちこちバグがふえていく
  * すぐに収拾がつかなくなる
  * 人間もよくやりますね
* 人間と同じということは、人間と同じ対策が使えるのでこれまでの人間用のプロセスが使える
  * AIがコードを読むときも人間と同じヒント(クラス設計、コメント)を見て読んでいるので、人間が読みやすいコードはAIにも読みやすい
* 全部任せきりで大丈夫と言っている意見もよく見かけますけどね
  * うまくいく方法があるなら、具体的に教えてほしいところです
  * それでうまくいくなら、それに越したことはないですけどね
#### TDDなどの手順を逐一指示して実行してもらう
* TDD
  * Red Green Refactoringの繰り返しで進める
  * Red 失敗するテストを書く
    * ここで呼び出しやすいAPIを決めてしまう
    * 必ず失敗することを確認する
  * Green 実行する最低限のコードを書く
    * 読みやすさは気にしない
    * 余計な配慮はいったんは我慢する
  * Refactoring 
    * 壊れないように適切な手順を守りながら、きれいに書き直す
    * 壊れたらすぐわかるよう、自動テストをどんどん実行しながら進める
* 人間が作り出したプログラム作成のプロセスのうち、今生き残っているのはTDDなのでそれを利用すればよい
  * 過去は詳細設計という手法もありましたが、今の開発には向かない
* Red Green Refactoringのサイクルを意識して書いてもらう
  * 意識してくれないので、今書くべきはコードじゃないと何度も言わないといけない
    * 「いまはRedですからテストファーストでお願いしますね。」
  * 気を付けないといけないところも同じ
    * Redでは必要な仕様に合った例になっているかを確認する必要がある
      * 仕様を勘違いされていたら間違ったコードしかできない
      * ここで仕様をすべて明記する必要があるのは人間と同じ
    * Greenでは余計なコードまで書かないように注意しておく必要がある
      * ここで付け足したコードはテストで機能が担保されていないのは人間がやるのと同じ
    * Refactoringは今のところ任せられないです
      * 簡単なものならやってくれるかも
      * 人間が読めなくてリファクタリングできないコードのとっかかりならやってくれます
## 6. AIによるプログラミングを学ぶ上で
- 今の最適解はすぐに廃れます
  - 1年後には結構状況が変わっていると思いますよ
- AIにできるようになったことはどんどん任せないと
  - AIより精度の悪いことを時間かけてやっていても仕方ない
- 何が廃れるかを予想して体系を組み立てていくのが大事
  - ハルシネーションを繰り返す
    - 回答の自信を測る方法はわかっている
    - 正しい回答を検索する方法も身に着けている
    - 時間の問題で解決する
  - TDDをやってくれない
    - TDDの学習データが少ない
    - TDDに合わせた学習データをうまく用意してやればよい
    - 数年で解決のめどは立っている
  - 演繹思考が苦手
    - 現在のアルゴリズムに演繹を埋め込む余地がない
    - 10年単位で解決する見込みがない
- まあ当たるとは限りませんがね。
- 予測しながら学習を進めることが大事。
- 「AIの気持ち」を理解できるようになることが大事です
  - 何がわかって何がわからないのかを把握しながら理解すればより良い方法が見つかります。
  - 将来にわたって役に立つことが何かもわかります。